import torch
import torch.nn as nn
from transformers import AutoModel, AutoTokenizer
import os
import warnings
import logging

# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø WARNINGS
# ============================================================================

# –ü–æ–¥–∞–≤–∏—Ç—å –≤—Å–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)

# –ü–æ–¥–∞–≤–∏—Ç—å –ª–∏—à–Ω–∏–µ –ª–æ–≥–∏ –æ—Ç HuggingFace –∏ PyTorch
logging.getLogger("transformers").setLevel(logging.ERROR)
logging.getLogger("huggingface_hub").setLevel(logging.ERROR)
logging.getLogger("torch").setLevel(logging.ERROR)

# ============================================================================
# –ö–û–ù–°–¢–ê–ù–¢–´
# ============================================================================

THRESHOLD = 0.6
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
MODEL_DIR = os.path.join(os.path.dirname(__file__), "models")
DEFAULT_MODEL_PATH = os.path.join(MODEL_DIR, "rubert_siamese_model.pth")


# ============================================================================
# –ú–û–î–ï–õ–¨
# ============================================================================

class SiameseRuBERT(nn.Module):
    """
    Siamese –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–∞ –±–∞–∑–µ RuBERT –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –ø–æ—Ö–æ–∂–µ—Å—Ç–∏
    –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–Ω–∫–∞—Ç–µ–Ω—Ü–∏—é embeddings –∏ –∏—Ö —Ä–∞–∑–Ω–æ—Å—Ç–∏.
    """

    def __init__(self, model_name="DeepPavlov/rubert-base-cased"):
        super(SiameseRuBERT, self).__init__()
        self.bert = AutoModel.from_pretrained(model_name)
        hidden_size = self.bert.config.hidden_size  # 768 –¥–ª—è base-–º–æ–¥–µ–ª–µ–π

        self.classifier = nn.Sequential(
            nn.Linear(hidden_size * 3, 512),  # 768*3=2304
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward_one(self, inputs):
        """
        –ü–æ–ª—É—á–∏—Ç—å embedding —Ç–µ–∫—Å—Ç–∞ –∏–∑ [CLS] —Ç–æ–∫–µ–Ω–∞

        Args:
            inputs: dict —Å 'input_ids' –∏ 'attention_mask'

        Returns:
            Tensor —Ä–∞–∑–º–µ—Ä–∞ (batch_size, hidden_size)
        """
        outputs = self.bert(
            input_ids=inputs['input_ids'],
            attention_mask=inputs['attention_mask']
        )
        # –ë–µ—Ä–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ [CLS] —Ç–æ–∫–µ–Ω–∞ (–ø–µ—Ä–≤—ã–π —Ç–æ–∫–µ–Ω –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
        cls_embedding = outputs.last_hidden_state[:, 0, :]
        return cls_embedding

    def forward(self, doc1_inputs, doc2_inputs):
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏

        Args:
            doc1_inputs: dict —Å —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–µ—Ä–≤—ã–º —Ç–µ–∫—Å—Ç–æ–º
            doc2_inputs: dict —Å —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤—Ç–æ—Ä—ã–º —Ç–µ–∫—Å—Ç–æ–º

        Returns:
            Tensor —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ (batch_size, 1)
        """
        emb1 = self.forward_one(doc1_inputs)
        emb2 = self.forward_one(doc2_inputs)

        # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è —Å–∏–∞–º—Å–∫–∞—è –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è:
        # [embedding1, embedding2, |embedding1 - embedding2|]
        combined_features = torch.cat(
            (emb1, emb2, torch.abs(emb1 - emb2)),
            dim=1
        )

        return self.classifier(combined_features)


# ============================================================================
# –ó–ê–ì–†–£–ó–ö–ê –ò –ò–ù–§–ï–†–ï–ù–°
# ============================================================================

class SiameseInference:
    """
    –£–¥–æ–±–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ Siamese RuBERT –º–æ–¥–µ–ª–∏
    """

    def __init__(self, model_path, model_name="DeepPavlov/rubert-base-cased"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä

        Args:
            model_path: –ø—É—Ç—å –∫ .pth —Ñ–∞–π–ª—É —Å –≤–µ—Å–∞–º–∏ –º–æ–¥–µ–ª–∏
            model_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ RuBERT –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        """
        self.device = DEVICE
        self.model = self._load_model(model_path, model_name)
        self.tokenizer = AutoTokenizer.from_pretrained("cointegrated/rubert-tiny2")

    def _load_model(self, model_path, model_name):
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑ checkpoint

        Args:
            model_path: –ø—É—Ç—å –∫ .pth —Ñ–∞–π–ª—É
            model_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏

        Returns:
            Model –≤ eval —Ä–µ–∂–∏–º–µ –Ω–∞ –Ω—É–∂–Ω–æ–º device
        """
        model = SiameseRuBERT(model_name=model_name)
        model.load_state_dict(torch.load(model_path, map_location=self.device))
        model.to(self.device)
        model.eval()
        return model

    def predict(self, text1: str, text2: str, return_logits=False) -> float:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤

        Args:
            text1: –ø–µ—Ä–≤—ã–π —Ç–µ–∫—Å—Ç
            text2: –≤—Ç–æ—Ä–æ–π —Ç–µ–∫—Å—Ç
            return_logits: –µ—Å–ª–∏ True, –≤–µ—Ä–Ω—É—Ç—å —Å—ã—Ä—ã–µ –ª–æ–≥–∏—Ç—ã, –∏–Ω–∞—á–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å

        Returns:
            –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ (0..1) –∏–ª–∏ –ª–æ–≥–∏—Ç
        """
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
        inputs1 = self.tokenizer(
            text1,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        )
        inputs2 = self.tokenizer(
            text2,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        )

        # –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –Ω–∞ device
        inputs1 = {k: v.to(self.device) for k, v in inputs1.items()}
        inputs2 = {k: v.to(self.device) for k, v in inputs2.items()}

        # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
        with torch.no_grad():
            logits = self.model(inputs1, inputs2)

        # –í–µ—Ä–Ω—É—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        probability = logits.item()
        return probability

    def predict_batch(self, text_pairs: list) -> list:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –±–∞—Ç—á–∞ –ø–∞—Ä —Ç–µ–∫—Å—Ç–æ–≤

        Args:
            text_pairs: —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (text1, text2)

        Returns:
            –°–ø–∏—Å–æ–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        """
        probabilities = []
        for text1, text2 in text_pairs:
            prob = self.predict(text1, text2)
            probabilities.append(prob)
        return probabilities

    def is_similar(self, text1: str, text2: str, threshold=THRESHOLD) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –ø–æ—Ö–æ–∂–∏ –ª–∏ —Ç–µ–∫—Å—Ç—ã (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)

        Args:
            text1: –ø–µ—Ä–≤—ã–π —Ç–µ–∫—Å—Ç
            text2: –≤—Ç–æ—Ä–æ–π —Ç–µ–∫—Å—Ç
            threshold: –ø–æ—Ä–æ–≥ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.6)

        Returns:
            True –µ—Å–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å >= threshold, –∏–Ω–∞—á–µ False
        """
        probability = self.predict(text1, text2)
        return probability >= threshold


# ============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –û–ë–†–ê–¢–ù–û–ô –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
# ============================================================================

_inference_instance = None


def load_model(path_to_pth: str = None, model_name="DeepPavlov/rubert-base-cased") -> SiameseInference:
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑ checkpoint

    Args:
        path_to_pth: –ø—É—Ç—å –∫ .pth —Ñ–∞–π–ª—É —Å –≤–µ—Å–∞–º–∏ –º–æ–¥–µ–ª–∏
                    –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç DEFAULT_MODEL_PATH (ml_model/models/rubert_siamese_model.pth)
        model_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ RuBERT

    Returns:
        –û–±—ä–µ–∫—Ç SiameseInference

    Raises:
        FileNotFoundError: –µ—Å–ª–∏ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
    """
    global _inference_instance

    if path_to_pth is None:
        path_to_pth = DEFAULT_MODEL_PATH

    if not os.path.exists(path_to_pth):
        raise FileNotFoundError(
            f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {path_to_pth}\n"
            f"üìÅ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤: {MODEL_DIR}/"
        )

    print(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑: {path_to_pth}")
    _inference_instance = SiameseInference(path_to_pth, model_name)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {DEVICE}")
    return _inference_instance


def predict(text1: str, text2: str) -> float:
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤
    –¢—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ load_model()

    Args:
        text1: –ø–µ—Ä–≤—ã–π —Ç–µ–∫—Å—Ç
        text2: –≤—Ç–æ—Ä–æ–π —Ç–µ–∫—Å—Ç

    Returns:
        –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ (0..1)

    Raises:
        RuntimeError: –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
    """
    if _inference_instance is None:
        raise RuntimeError(
            "‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏—Ç–µ load_model()"
        )
    return _inference_instance.predict(text1, text2)


# ============================================================================
# –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø
# ============================================================================

if __name__ == "__main__":
    # –í–∞—Ä–∏–∞–Ω—Ç 1: –ß–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏–∏ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)
    print("=== –í–∞—Ä–∏–∞–Ω—Ç 1: load_model() –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ ===")
    try:
        model_inf = load_model()  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑ ml_model/models/
        prob = predict(
            "–≠—Ç–æ –ø–µ—Ä–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è",
            "–≠—Ç–æ –ø–æ—Ö–æ–∂–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"
        )
        print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç–∏: {prob:.4f}\n")
    except FileNotFoundError as e:
        print(f"–û—à–∏–±–∫–∞: {e}\n")

    # –í–∞—Ä–∏–∞–Ω—Ç 2: –ß–µ—Ä–µ–∑ –∫–ª–∞—Å—Å SiameseInference
    print("=== –í–∞—Ä–∏–∞–Ω—Ç 2: SiameseInference ===")
    try:
        inference = SiameseInference(DEFAULT_MODEL_PATH)

        text1 = "–ú–æ—Å–∫–≤–∞ - —Å—Ç–æ–ª–∏—Ü–∞ –†–æ—Å—Å–∏–∏"
        text2 = "–†–æ—Å—Å–∏—è –∏–º–µ–µ—Ç —Å—Ç–æ–ª–∏—Ü—É –ú–æ—Å–∫–≤—É"

        prob = inference.predict(text1, text2)
        print(f"–¢–µ–∫—Å—Ç 1: {text1}")
        print(f"–¢–µ–∫—Å—Ç 2: {text2}")
        print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç–∏: {prob:.4f}")
        print(f"–ü–æ—Ö–æ–∂–∏ –ª–∏? {inference.is_similar(text1, text2)} (–ø–æ—Ä–æ–≥: {THRESHOLD})\n")

        # –ë–∞—Ç—á –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
        print("=== –ë–∞—Ç—á –∏–Ω—Ñ–µ—Ä–µ–Ω—Å ===")
        pairs = [
            ("–ö–æ—Ç —Å–∏–¥–∏—Ç –Ω–∞ —Å—Ç–æ–ª–µ", "–ö–æ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ —Å—Ç–æ–ª–µ"),
            ("–ö—Ä–∞—Å–∏–≤–∞—è –ø–æ–≥–æ–¥–∞", "–ò–¥–µ—Ç –¥–æ–∂–¥—å"),
        ]
        probs = inference.predict_batch(pairs)
        for (t1, t2), prob in zip(pairs, probs):
            print(f"{t1} <-> {t2}: {prob:.4f}")

    except FileNotFoundError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")